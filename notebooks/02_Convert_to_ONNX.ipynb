{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e26db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import platformdirs\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import onnxruntime\n",
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "from onnxruntime.quantization.preprocess import quant_pre_process\n",
    "\n",
    "from katago_onnx.utils import load_model\n",
    "from katago_onnx.utils import load_sgf\n",
    "from katago_onnx.utils import featurize\n",
    "\n",
    "cache_dir = Path(platformdirs.user_cache_dir(\"katago-onnx\"))\n",
    "\n",
    "# Load model\n",
    "network_name = \"kata1-b28c512nbt-adam-s11165M-d5387M\"\n",
    "model_path = cache_dir / network_name / \"model.ckpt\"\n",
    "model = load_model(model_path, device=\"cpu\")\n",
    "\n",
    "onnx_model_path = cache_dir / network_name / \"model.onnx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c60640c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fk/ty303kmn61x3y013qnk89g3h0000gn/T/ipykernel_53205/3023177024.py:38: DeprecationWarning: You are using the legacy TorchScript-based ONNX export. Starting in PyTorch 2.9, the new torch.export-based ONNX exporter will be the default. To switch now, set dynamo=True in torch.onnx.export. This new exporter supports features like exporting LLMs with DynamicCache. We encourage you to try it and share feedback to help improve the experience. Learn more about the new export logic: https://pytorch.org/docs/stable/onnx_dynamo.html. For exporting control flow: https://pytorch.org/tutorials/beginner/onnx/export_control_flow_model_to_onnx_tutorial.html.\n",
      "  torch.onnx.export(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/hadim/model.onnx'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare inputs for ONNX export\n",
    "bin_input = torch.randn(1, 22, 19, 19, dtype=torch.float32)\n",
    "global_input = torch.randn(1, 19, dtype=torch.float32)\n",
    "model_inputs = (bin_input, global_input)\n",
    "\n",
    "# Define input and output names\n",
    "input_names = [\"bin_input\", \"global_input\"]\n",
    "output_names = [\n",
    "    \"policy\",\n",
    "    \"value\",\n",
    "    \"miscvalue\",\n",
    "    \"moremiscvalue\",\n",
    "    \"ownership\",\n",
    "    \"scoring\",\n",
    "    \"futurepos\",\n",
    "    \"seki\",\n",
    "    \"scorebelief\",\n",
    "]\n",
    "\n",
    "# Define dynamic axes (for dynamo=False)\n",
    "dynamic_axes = {\n",
    "    \"bin_input\": {0: \"batch_size\", 2: \"height\", 3: \"width\"},\n",
    "    \"global_input\": {0: \"batch_size\"},\n",
    "    \"policy\": {0: \"batch_size\", 2: \"moves\"},\n",
    "    \"value\": {0: \"batch_size\"},\n",
    "    \"miscvalue\": {0: \"batch_size\"},\n",
    "    \"moremiscvalue\": {0: \"batch_size\"},\n",
    "    \"ownership\": {0: \"batch_size\", 2: \"height\", 3: \"width\"},\n",
    "    \"scoring\": {0: \"batch_size\", 2: \"height\", 3: \"width\"},\n",
    "    \"futurepos\": {0: \"batch_size\", 2: \"height\", 3: \"width\"},\n",
    "    \"seki\": {0: \"batch_size\", 2: \"height\", 3: \"width\"},\n",
    "    \"scorebelief\": {0: \"batch_size\"},\n",
    "}\n",
    "\n",
    "# Export the model to ONNX\n",
    "# Note: We use dynamo=False because dynamo=True currently fails with\n",
    "# \"No ONNX function found for aten.sym_size.int\" for this model's dynamic shapes.\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    model_inputs,\n",
    "    onnx_model_path,\n",
    "    input_names=input_names,\n",
    "    output_names=output_names,\n",
    "    dynamic_axes=dynamic_axes,\n",
    "    opset_version=17,\n",
    "    dynamo=False,\n",
    ")\n",
    "\n",
    "shutil.copy(onnx_model_path, \"/Users/hadim/model.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ea96b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing model to /Users/hadim/Library/Caches/katago-onnx/kata1-b28c512nbt-adam-s11165M-d5387M/model.prep.onnx...\n",
      "Quantizing model to /Users/hadim/Library/Caches/katago-onnx/kata1-b28c512nbt-adam-s11165M-d5387M/model.quant.onnx...\n",
      "Quantizing model to /Users/hadim/Library/Caches/katago-onnx/kata1-b28c512nbt-adam-s11165M-d5387M/model.quant.onnx...\n",
      "Quantized model saved to: /Users/hadim/Library/Caches/katago-onnx/kata1-b28c512nbt-adam-s11165M-d5387M/model.quant.onnx\n",
      "Quantized model saved to: /Users/hadim/Library/Caches/katago-onnx/kata1-b28c512nbt-adam-s11165M-d5387M/model.quant.onnx\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/hadim/model.quant.onnx'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define paths\n",
    "model_fp32 = onnx_model_path\n",
    "model_prep = onnx_model_path.with_suffix(\".prep.onnx\")\n",
    "model_quant = onnx_model_path.with_suffix(\".quant.onnx\")\n",
    "\n",
    "# Pre-process the model (Shape inference and optimization)\n",
    "# This is recommended before quantization to ensure best results, especially for dynamic shapes\n",
    "print(f\"Pre-processing model to {model_prep}...\")\n",
    "quant_pre_process(model_fp32, model_prep)\n",
    "\n",
    "# Quantize the model (Int8)\n",
    "# This reduces the size by ~4x by converting weights from Float32 to Int8\n",
    "print(f\"Quantizing model to {model_quant}...\")\n",
    "quantize_dynamic(\n",
    "    model_input=model_prep,\n",
    "    model_output=model_quant,\n",
    "    weight_type=QuantType.QUInt8,  # Quantize weights to Unsigned Int8\n",
    ")\n",
    "\n",
    "print(f\"Quantized model saved to: {model_quant}\")\n",
    "\n",
    "# Copy to home for easy access\n",
    "shutil.copy(model_quant, \"/Users/hadim/model.quant.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "752e0f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded SGF with 117 moves.\n",
      "Game size: 13\n",
      "Replayed to move 8\n",
      "Winrate: 0.5851287245750427\n",
      "Score Lead: 0.2296016365289688\n",
      "(1, 6, 170)\n",
      "(1, 3)\n",
      "(1, 10)\n",
      "(1, 8)\n",
      "(1, 1, 13, 13)\n",
      "(1, 1, 13, 13)\n",
      "(1, 2, 13, 13)\n",
      "(1, 4, 13, 13)\n",
      "(1, 842)\n",
      "(1, 6, 170)\n",
      "(1, 3)\n",
      "(1, 10)\n",
      "(1, 8)\n",
      "(1, 1, 13, 13)\n",
      "(1, 1, 13, 13)\n",
      "(1, 2, 13, 13)\n",
      "(1, 4, 13, 13)\n",
      "(1, 842)\n",
      "Winrate: 0.5851287245750427\n",
      "Score Lead: 0.2296016365289688\n",
      "(1, 6, 170)\n",
      "(1, 3)\n",
      "(1, 10)\n",
      "(1, 8)\n",
      "(1, 1, 13, 13)\n",
      "(1, 1, 13, 13)\n",
      "(1, 2, 13, 13)\n",
      "(1, 4, 13, 13)\n",
      "(1, 842)\n",
      "(1, 6, 170)\n",
      "(1, 3)\n",
      "(1, 10)\n",
      "(1, 8)\n",
      "(1, 1, 13, 13)\n",
      "(1, 1, 13, 13)\n",
      "(1, 2, 13, 13)\n",
      "(1, 4, 13, 13)\n",
      "(1, 842)\n"
     ]
    }
   ],
   "source": [
    "target_move = 8\n",
    "\n",
    "# Path to SGF\n",
    "sgf_path = \"../sgf/game-19-white-38.sgf\"\n",
    "sgf_path = \"../sgf/game-13-white-12.sgf\"\n",
    "# sgf_path = \"../sgf/game-9-white-19.sgf\"\n",
    "\n",
    "# Load game state from SGF\n",
    "gamestate = load_sgf(sgf_path, target_move=target_move)\n",
    "\n",
    "# Featurize the game state\n",
    "features, bin_input, global_input = featurize(gamestate, model)\n",
    "\n",
    "# Prepare  inputs for ONNX export\n",
    "model_inputs = (bin_input, global_input)\n",
    "onnx_inputs = [tensor.numpy(force=True) for tensor in model_inputs]\n",
    "\n",
    "ort_session = onnxruntime.InferenceSession(\n",
    "    onnx_model_path,\n",
    "    providers=[\"CPUExecutionProvider\"],\n",
    ")\n",
    "\n",
    "onnxruntime_input = {\n",
    "    input_arg.name: input_value for input_arg, input_value in zip(ort_session.get_inputs(), onnx_inputs)\n",
    "}\n",
    "\n",
    "# ONNX Runtime returns a list of outputs\n",
    "onnxruntime_outputs = ort_session.run(None, onnxruntime_input)\n",
    "\n",
    "# Unpack outputs\n",
    "policy_logits = np.array(onnxruntime_outputs[0])\n",
    "value_logits = np.array(onnxruntime_outputs[1])\n",
    "\n",
    "# Process Policy\n",
    "# policy_logits is already numpy from ONNX Runtime\n",
    "# Shape: [batch, num_policy_outputs, num_moves]\n",
    "# We want the first policy output (index 0) and softmax over moves (axis 2)\n",
    "policy_probs = np.exp(policy_logits[:, 0, :]) / np.sum(np.exp(policy_logits[:, 0, :]), axis=1, keepdims=True)\n",
    "policy_probs = policy_probs[0]\n",
    "\n",
    "# Process Value (Winrate)\n",
    "# value_logits is already numpy from ONNX Runtime\n",
    "# Shape: [batch, 3] corresponding to [win, loss, no_result]\n",
    "value_probs = np.exp(value_logits) / np.sum(np.exp(value_logits), axis=1, keepdims=True)\n",
    "value_probs = value_probs[0]\n",
    "\n",
    "winrate = value_probs[0]  # Assuming index 0 is win for current player? Or black? Or white?\n",
    "\n",
    "# Process Score Lead\n",
    "# miscvalue_logits is at index 2\n",
    "miscvalue_logits = np.array(onnxruntime_outputs[2])\n",
    "# Index 2 of miscvalue is lead\n",
    "score_lead = miscvalue_logits[0, 2] * model.lead_multiplier\n",
    "\n",
    "print(f\"Winrate: {winrate}\")\n",
    "print(f\"Score Lead: {score_lead}\")\n",
    "\n",
    "for a in onnxruntime_outputs:\n",
    "    print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7e963a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(0.5851287)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c18532a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
